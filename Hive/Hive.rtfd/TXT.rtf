{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 ArialMT;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red27\green29\blue31;\red255\green255\blue255;\red235\green236\blue237;
}
{\*\expandedcolortbl;;\cssrgb\c14118\c15294\c16078;\cssrgb\c100000\c100000\c100000;\cssrgb\c93725\c94118\c94510;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww14000\viewh15140\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \

\fs36 The term \'91Big Data\'92 is used for collections of large datasets that include huge volumes, high velocity and a variety of data is increasing day by day.  Using traditional data management systems, I is difficult to process Big Data. Thats why Hadoop framework came into the picture.\
\
Hadoop is an open-source framework to store and process Big Data in a distributed environment. It contains two modules:\
\
1. HDFS - Hadoop Distributed File System\
This ia a part of Hadoop framework, used to store and process the datasets. It provides a fault-tolerant file system to run on commodity hardware.\
\
2. MapReduce\
It is parallel programming model for processing large amounts of structured, semi-structured and unstructured data on large clusters of commodity hardware.\
\
The Hadoop ecosystem contains different sub-projects(tools) such as SQOOP, PIG and HIVE that are used to help Hadoop modules.\
\
\
SQOOP:\
It is used to import and export data to and from between HDFS and RDBMS\
\
PIG:\
It is a procedural language platform used to develop a script for MapReduce operations.\
\
HIVE:\
It is a platform used to develop SQL type scripts to do MapReduce operations\
\
There are various ways to execute MapReduce operations:\
The traditional approach using Java MapReduce program for structured, semi-structured and unstructured data.\
\
The scripting approach for MapReduce to process structured, semi-structured and unstructured data.\
\
The Hive Query Language (HiveQL or HQL) for MapReduce to process structured data using hive.\
\
What is HIVE:\
Hive is a data warehouse infrastructure tool to process structured data in Hadoop. It resides on top of Hadoop to summarise Big Data, and makes querying and analyzing easy.\
\
Initially Hive was developed by facebook, later the Apache Software Foundation took it up and developed it further as an open source under the name Apache Hive. It is used by different companies.\
\
Amazon uses Hive in Amazon Elastic MapReduce.\
\
\
Hive is not:\
A relational database\
A design for online transaction processing(OLTP)\
A language for real-time queries and low-level updates.\
\
Features of Hive:\
It stores schema in a database and processed data into HDFS.\
It is designed for OLAP\
It provides SQL type language for querying called HIveQL or HQL\
It is familiar, fast, scalable and extensible\
\
\
Hive used to querying and managing large datasets residing in distributed storage. Before becoming an open source project of Apache Hadoop, Hive was originated in Facebook. It provides a mechanism to project structure onto the data in Hadoop and to query that data using a SQL-like language called HIveQL(HQL)\
\
Hive is used because the tables in Hive are similar to tables in a relational database. If you are familiar with SQL, it\'92s a cakewalk. Many users can simultaneously query the data using Hive-QL.\
\
What is HQL?\
Hive defines a simple SQL-like query language to querying and managing large datasets called Hive-QL(HQL). Its easy to use if you\'92re familiar with SQL Language. Hive allows programmers who are familiar with the language to write the custom MapReduce framework to perform more sophisticated analysis.\
\
Uses of Hive:\
The Apache Hive Distributed storage.\
Hive provides tools to enable easy data extract/transform/load (ETL)\
It provides the structure on a variety of data formats.\
By using Hive, we can access files stored in HDFA or in other data storage systems such as Apache HBase.\
\
Limitations of Hive:\
Hive is not designed for Online Transaction Processing(OLTP), it is only used for the Online Analytical Processing(OLAP).\
Hive Supports overwriting or apprehending data, but not updates and deletes.\
In Hive, sub queries are not supported.\
\
Why Hive is used inspire of PIG?\
The following are the reasons why Hive is used in spite of Pig\'92s availability:\
HIve-QL is a declarative language line SQL, PigLatin is a data flow language.\
Pig: a data-flow and environment for exploring very large datasets.\
Hive: a distributed data warehouse.\
\
Components of Hive:\
Metastore:\
Hive stores the schema of the Hive tables in a Hive Metastore. Metastore is used to hold all the information about the tables and partitions that arena the warehouse. By default, the megastore is run in the same process as the Hive service and the default Metastore is DerBy Database.\
\
SerDe:\
Serializer, Deserializer gives instructions to hive on how to process a record. \
\
\
Hive Commands:\
Data Definition Language(DDL):\
DDL statements are used to build and modify the tables and other objects in the database.\
\
CREATE\
DROP\
TRUNCATE\
ALTER\
SHOW\
DESCRIBE\
\
\
CREATE DATABASE projectdb;\
\
SHOW DATABASES;\
\
The database creates in a default location of the Hive warehouse. IN cloudera, Hive databases store in a /user/hive/warehouse\
\
Use projectdb;\
\
There are 2 types of tables in Hive, Internal and external.\
\
Creating internal table:\
Internal table are like normal database table where data can be stored and queried on. On dropping these tables the data stored in them also gets deleted and data is lost forever. So one should be careful while using internal tables as one drop command can destroy the whole data. \
\
CREATE TABLE IF NOT EXISTS employee (EmpID string, Name string, Band string, DepartmentID string, Salary int)\
COMMENT \'93Employee Details\'94\
ROW FORMAT DELIMITED\
FIELDS TERMINATED BY \'93,\'94\
LINES TERMINATED BY \'93\\n\'94\
STORED AS TESTFILE;\
\
\
\pard\pardeftab720\partightenfactor0

\f1\fs30 \cf2 \cb3 \expnd0\expndtw0\kerning0
Sorry there is no primary key in hive if you have any other functionality related to hive table got through this\
\
\pard\pardeftab720\partightenfactor0

\f2\fs26 \cf2 \cb4 CREATE TABLE IF NOT EXISTS employee ( eid int, name String,\
 salary String, destination String)\
 COMMENT "Employee details"\
 ROW FORMAT DELIMITED\
 FIELDS TERMINATED BY "\\t"\
 LINES TERMINATED BY "\\n"\
 STORED AS TEXTFILE;  \
\
LOAD DATA LOCAL INPATH '/home/user/sample.txt'\
    OVERWRITE INTO TABLE employee;\
\
ALTER TABLE employee RENAME TO emp;\
\
desc tablename;\
\
ALTER TABLE employee CHANGE name ename String;\
hive> ALTER TABLE employee CHANGE salary salary Double;\
\
ALTER TABLE employee ADD COLUMNS ( \
    dept STRING COMMENT 'Department name');    \
\
ALTER TABLE employee REPLACE COLUMNS ( \
    eid INT empid Int, \
    ename STRING name String);\
\
DROP TABLE IF EXISTS employee;\
\
SHOW TABLES;\
\
SELECT * FROM employee WHERE Salary>40000 && Dept=TP;  \
\
CREATE VIEW emp_30000 AS\
    SELECT * FROM employee\
    WHERE salary>30000;\
\
DROP VIEW emp_30000;  
\f0\fs36 \cf0 \cb1 \kerning1\expnd0\expndtw0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
SHOW TABLES;\
\
\
\pard\pardeftab720\partightenfactor0

\f1\fs30 \cf2 \cb3 \expnd0\expndtw0\kerning0
If we want to see the columns names of the table in HiveQl, the following hive conf property should be set to true.\cf2 \cb1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf0 \kerning1\expnd0\expndtw0 \
hive> set hive.cli.print.header=true;\
\
\
\
\

\fs28 \
\
\
\
\
\
\
\
}